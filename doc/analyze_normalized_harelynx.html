<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Connection analysis of hare/lynx capture data</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>



<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h1>Connection analysis of hare/lynx capture data</h1>

<p>First install the <em>layeranalyzer</em> package. If you have <em>devtools</em> installed,
this can be achived by the command:</p>

<blockquote>
<p>install_github(repo=&ldquo;trondreitan/layeranalyzer&rdquo;)</p>
</blockquote>

<p>If devtools is not available, you need to reference the correct version:</p>

<blockquote>
<p>install.packages(&ldquo;<a href="https://github.com/trondreitan/layeranalyzer/raw/master/layeranalyzer_0.1.0.tar.gz%22,type=%22source%22,verbose=T">https://github.com/trondreitan/layeranalyzer/raw/master/layeranalyzer_0.1.0.tar.gz&rdquo;,type=&ldquo;source&rdquo;,verbose=T</a>)</p>
</blockquote>

<p>The personal web page has newer &ldquo;bleeding edge&rdquo; versions of the package:</p>

<blockquote>
<p>install.packages(&ldquo;<a href="https://folk.uio.no/trondr/R/layeranalyzer_0.1.0.tar.gz%22,type=%22source%22,verbose=T">https://folk.uio.no/trondr/R/layeranalyzer_0.1.0.tar.gz&rdquo;,type=&ldquo;source&rdquo;,verbose=T</a>)</p>
</blockquote>

<h2>If the package is installed, load it:</h2>

<pre><code class="r">library(layeranalyzer)
</code></pre>

<h2>Next, normalize the data</h2>

<p>This also provides us with functions for transforming back:
&ldquo;invtrans.hare&rdquo; and &ldquo;invtrans.lynx&rdquo;.
PS: This whole chunk is unnecessary for the analysis, since the
resulting datasets, &#39;hare.norm&#39; and &#39;lynx.norm&#39; are already included
in the package. However, in order to do the plots, the inverse transform
functions have to be defined.</p>

<pre><code class="r"># Read data (this is not necessary, as the data is already
# included in the package, and has thus been commented out).
#hare.orig=read.table(&quot;hare.txt&quot;,sep=&quot; &quot;)
#lynx.orig=read.table(&quot;lynx.txt&quot;,sep=&quot; &quot;)
names(hare.orig)=c(&quot;year&quot;,&quot;val&quot;)
names(lynx.orig)=c(&quot;year&quot;,&quot;val&quot;)

# Make copies that will be normalized:
hare.norm.struct=hare.orig
lynx.norm.struct=lynx.orig

# Log-transform:
hare.norm.struct$val=log(hare.orig$val)
lynx.norm.struct$val=log(lynx.orig$val)

# Test normality
shapiro.test(hare.norm.struct$val)
#no
shapiro.test(lynx.norm.struct$val)
#maybe?


# Transform hare data:
y=hare.norm.struct$val

# Make cumulative density approximation:
# First, determine accuracy from the range of the data.
scale=10^ceiling(log10(max(y)-min(y)))
# Density approximation from R&#39;s kernel density estimation method:
dd.hare=density(y, n=100001, from=min(y)-scale, to=max(y)+scale, adjust=1) 
dd.hare$F=cumsum(dd.hare$y)*(dd.hare$x[2]-dd.hare$x[1])
dd.hare$F=dd.hare$F/max(dd.hare$F)

# Transform values to something standard normalized-like:
trans.hare=function(numhares)
  qnorm(dd.hare$F[max(which(dd.hare$x&lt;numhares))])

# Transform values back again:
invtrans.hare=function(normhares)
  dd.hare$x[min(which(dd.hare$F&gt;pnorm(normhares)))]

# Transform data:
x=0*y
for(i in 1:length(x))
  x[i]=trans.hare(y[i])
# Put into table:
hare.norm.struct[,2]=x


# Try transforming back:
z=0*y
for(i in 1:length(x))
  z[i]=invtrans.hare(x[i])
# Comparison with x goes well...

# Write transformed hare data to file (commented out):
# write(t(as.matrix(hare.norm.struct)),file=&quot;hare_norm.txt&quot;,ncolumns=2)



# Transform lynx data:
y=lynx.norm.struct$val

# Make cumulative density approximation:
# First, determine accuracy from the range of the data.
scale=10^ceiling(log10(max(y)-min(y)))
# Density approximation from R&#39;s kernel density estimation method:
dd.lynx=density(y, n=100001, from=min(y)-scale, to=max(y)+scale, adjust=1) 
dd.lynx$F=cumsum(dd.lynx$y)*(dd.lynx$x[2]-dd.lynx$x[1])
dd.lynx$F=dd.lynx$F/max(dd.lynx$F)

# Transform values to something standard normalized-like:
trans.lynx=function(numlynx)
  qnorm(dd.lynx$F[max(which(dd.lynx$x&lt;numlynx))])

# Transform values back again:
invtrans.lynx=function(normlynx)
  dd.lynx$x[min(which(dd.lynx$F&gt;pnorm(normlynx)))]

# Transform values to something standard normalized-like:
x=0*y
for(i in 1:length(x))
  x[i]=trans.lynx(y[i])
# Put into table:
lynx.norm.struct[,2]=x

# Write transformed lynx data to file (commented out):
# write(t(as.matrix(lynx.norm.struct)),file=&quot;lynx_norm.txt&quot;,ncolumns=2)

# Make into layer.data.series structures:
hare.norm=layer.data.series(time.points=hare.norm.struct$year,
  value.points=hare.norm.struct$val,name=&quot;hare&quot;)
lynx.norm=layer.data.series(time.points=lynx.norm.struct$year,
  value.points=lynx.norm.struct$val,name=&quot;lynx&quot;)
</code></pre>

<h2>Read data and define prior:</h2>

<p>How to read data from files, if available:
&#39;hare.norm=read.layer.data.series(&ldquo;hare_norm.txt&rdquo;,sep=&ldquo; &rdquo;,name=&ldquo;hare&rdquo;)&#39; and
&#39;lynx.norm=read.layer.data.series(&ldquo;lynx_norm.txt&rdquo;,sep=&ldquo; &rdquo;,name=&ldquo;lynx&rdquo;)&#39;.
These are however pre-defined in the &#39;layeranalyzer&#39; package).</p>

<h3>Plot data:</h3>

<pre><code class="r">plot(hare.norm$time,hare.norm$value,type=&quot;b&quot;,ylim=c(-3,3))
lines(lynx.norm$time,lynx.norm$value,type=&quot;b&quot;,col=&quot;red&quot;)
</code></pre>

<h3>Set priors:</h3>

<pre><code class="r">p.hare=layer.prior(mu=c(-1,1), init=c(-5,5),
  dt=c(0.5,5),sigma=c(0.01,2),obs=c(0.01,1),lin=c(-0.1,0.1), beta=c(-2,2))
p.lynx=layer.prior(mu=c(-1,1), init=c(-5,5),
  dt=c(0.5,20),sigma=c(0.01,2),obs=c(0.01,1),lin=c(-0.1,0.1), beta=c(-2,2))
</code></pre>

<h3>Initial standalone structure analysis.</h3>

<p>(Only mentioned in the main text)</p>

<pre><code class="r">models.hares=traverse.standalone.layered(hare.norm, max.layers=2, 
  talkative=TRUE, allow.one.feedback.loop=TRUE, 
  just.stationary=FALSE, no.rw=FALSE,    
  time.integrals.possible=FALSE, 
  allow.deterministic.layers=TRUE,
  use.stationary.stdev = FALSE, mcmc=TRUE,
  num.MCMC=1000,spacing=10,burnin=2000, num.temp = 4, prior=p.hare)
compare.layered(models.hares)

summary(models.hares[[5]])
#[1] &quot;summary called&quot;
#Coefficients:
#                        Mean    Median Lower 95% Upper 95%
#mu_hare             0.073010  0.083537 -0.378090  0.480828
#dt_hare_1           2.323119  2.151224  0.779086  4.912041
#sigma_hare_1        0.402682  0.408121  0.103110  0.696254
#dt_hare_2           4.086392  3.877787  1.981780  7.808524
#sigma_hare_2        0.981927  1.005536  0.180366  1.615923
#obs_sd_hare         0.211314  0.210086  0.071823  0.361114
#init_hare_l1_s0     1.737514  1.730336  1.308373  2.197310
#init_hare_l2_s0     1.341241  1.459415 -1.768511  3.844231
#beta_hare,1_hare,2 -1.419770 -1.391591 -3.027283  0.038752
#complex.eigen       0.934000  1.000000  0.000000  1.000000
#cycle01            18.857678 16.204408 10.588717 45.206529
#Model log-likelihood:   -71.079
</code></pre>

<pre><code class="r">models.lynx=traverse.standalone.layered(lynx.norm, max.layers=2, 
  talkative=TRUE, allow.one.feedback.loop=TRUE, 
  just.stationary=FALSE, no.rw=FALSE,    
  time.integrals.possible=FALSE, 
  allow.deterministic.layers=TRUE,
  use.stationary.stdev = FALSE, mcmc=TRUE,
  num.MCMC=1000,spacing=10,burnin=2000, num.temp = 4, prior=p.lynx)
compare.layered(models.lynx)
summary(models.lynx[[13]])
</code></pre>

<h3>Set priors sufficiently for connection analysis:</h3>

<pre><code class="r">p.hare=layer.prior(mu=c(-1,1), 
  dt=c(0.5,5),sigma=c(0.01,2),obs=c(0.01,1),beta=c(-2,2))
p.lynx=layer.prior(mu=c(-1,1), 
  dt=c(0.5,20),sigma=c(0.01,2),obs=c(0.01,1),beta=c(-2,2))
</code></pre>

<h3>Set structure to one-layered</h3>

<p>The process structure of each time series must be set, before
connection analysis can be started.</p>

<p>There is suspition that the standalone analysis of each time series
yielded 2-layered models because the extra layer for hares are the lynx and
the extra layer for lynx are the hares. Thus, we start with a 1-layered
(OU-like) process for each time series.</p>

<pre><code class="r">hare.struct=layer.series.structure(hare.norm, numlayers=1, prior=p.hare)
lynx.struct=layer.series.structure(lynx.norm, numlayers=1, prior=p.lynx)
</code></pre>

<h2>Traverse connection models between hares and lynx:</h2>

<p>PS: This will take some time.</p>

<pre><code class="r">res=traverse.connections.layered(hare.struct,lynx.struct, 
  num.MCMC=1000, burnin=10000, spacing=10,num.temp=10,T.ground=1.1,
 silent.mode=FALSE)
</code></pre>

<h3>Model comparison (using Bayesian model probabilities):</h3>

<pre><code class="r">compare.layered(res)
#           log(lik) Post. Prob.(%)
#Model   1 -109.6261        0.02093
#Model   2 -103.8030        7.07560
#Model   3 -108.9128        0.04272
#Model   4 -101.2288       92.83724
#Model   5 -109.5099        0.02351
</code></pre>

<p>Overwhelming support for model 4. Take a look at this:</p>

<pre><code class="r">summary(res[[4]])
#Coefficients:
#                        Mean    Median Lower 95% Upper 95%
#mu_hare            -0.026388 -0.026703 -0.426835  0.380152
#dt_hare_1           3.759316  3.581145  2.193782  6.320872
#sigma_hare_1        0.647815  0.644069  0.532804  0.800031
#obs_sd_hare         0.068970  0.050807  0.006233  0.224773
#mu_lynx            -0.021962 -0.019578 -0.386817  0.360592
#dt_lynx_1           5.138756  4.883584  2.888825  8.923214
#sigma_lynx_1        0.462834  0.456090  0.358721  0.592182
#obs_sd_lynx         0.049013  0.039922  0.006100  0.135660
#beta_hare,1_lynx,1  1.850127  1.770549  0.954505  3.046231
#beta_lynx,1_hare,1 -1.100573 -1.062133 -2.092366 -0.332004
#complex.eigen       0.998000  1.000000  1.000000  1.000000
#cycle01            21.576812 19.562330 13.378333 38.033484
#
#Model log-likelihood:  -101.229
</code></pre>

<p>Two-way causal link, positive from hares to lynx,
negative from lynx to hares. This seems reasonable!</p>

<h3>Run model with predictions forward in time:</h3>

<pre><code class="r">res4=layer.analyzer(hare.struct,lynx.struct,
  num.MCMC=1000, burnin=10000, spacing=10,num.temp=5,T.ground=1.1,
  causal=cbind(c(2,1,1,1),c(1,1,2,1)), 
  smoothing.specs=list(do.smoothing=TRUE, smoothing.time.diff = 0.1,
  smoothing.start = 1850, smoothing.end = 2018, 
  num.smooth.per.mcmc = 100, do.return.smoothing.samples = FALSE),
  return.residuals=TRUE)
</code></pre>

<h3>Make plot, using original scale:</h3>

<p>Plot hare data:</p>

<pre><code class="r">plot(hare.orig$year,hare.orig$val,xlim=c(1850,1960),
  log=&quot;y&quot;,ylim=c(500,200000),xlab=&quot;Year&quot;,ylab=&quot;#hares&quot;)
# Transform hare process inference back to original scale:
invtrans.hare.mean=res4$process.mean[1,]
for(i in 1:length(invtrans.hare.mean))
  invtrans.hare.mean[i]=exp(invtrans.hare(res4$process.mean[1,i]))
lines(res4$process.time.points, invtrans.hare.mean)
invtrans.hare.lower=res4$process.lower95[1,]
for(i in 1:length(invtrans.hare.mean))
  invtrans.hare.lower[i]=exp(invtrans.hare(res4$process.lower95[1,i]))
lines(res4$process.time.points, invtrans.hare.lower,col=&quot;red&quot;)
invtrans.hare.upper=res4$process.upper95[1,]
for(i in 1:length(invtrans.hare.mean))
  invtrans.hare.upper[i]=exp(invtrans.hare(res4$process.upper95[1,i]))
lines(res4$process.time.points, invtrans.hare.upper,col=&quot;red&quot;)
</code></pre>

<pre><code class="r">plot(hare.orig$year,hare.orig$val)
lines(res4$process.time.points, invtrans.hare.mean)
lines(res4$process.time.points, invtrans.hare.lower,col=&quot;red&quot;)
lines(res4$process.time.points, invtrans.hare.upper,col=&quot;red&quot;)
</code></pre>

<p>Plot Lynx:</p>

<pre><code class="r">plot(lynx.orig$year,lynx.orig$val,xlim=c(1850,1960),
  log=&quot;y&quot;,ylim=c(100,10000),xlab=&quot;Year&quot;,ylab=&quot;#lynx&quot;)
# Transform lynx process inference back to original scale:
invtrans.lynx.mean=res4$process.mean[2,]
for(i in 1:length(invtrans.lynx.mean))
  invtrans.lynx.mean[i]=exp(invtrans.lynx(res4$process.mean[2,i]))
lines(res4$process.time.points, invtrans.lynx.mean)
invtrans.lynx.lower=res4$process.lower95[2,]
for(i in 1:length(invtrans.lynx.mean))
  invtrans.lynx.lower[i]=exp(invtrans.lynx(res4$process.lower95[2,i]))
lines(res4$process.time.points, invtrans.lynx.lower,col=&quot;red&quot;)
invtrans.lynx.upper=res4$process.upper95[2,]
for(i in 1:length(invtrans.lynx.mean))
  invtrans.lynx.upper[i]=exp(invtrans.lynx(res4$process.upper95[2,i]))
lines(res4$process.time.points, invtrans.lynx.upper,col=&quot;red&quot;)
</code></pre>

<pre><code class="r">plot(lynx.orig$year,lynx.orig$val,log=&quot;y&quot;)
lines(res4$process.time.points, invtrans.lynx.mean)
lines(res4$process.time.points, invtrans.lynx.lower,col=&quot;red&quot;)
lines(res4$process.time.points, invtrans.lynx.upper,col=&quot;red&quot;)
</code></pre>

<h2>Look at residuals:</h2>

<p>Run model again, specifying that residuals are to be fetched:</p>

<pre><code class="r">res4=layer.analyzer(hare.struct,lynx.struct,
  num.MCMC=1000, burnin=10000, spacing=10,num.temp=1,T.ground=1.1,
  causal=cbind(c(2,1,1,1),c(1,1,2,1)),
  return.residuals=TRUE)
</code></pre>

<p>Fetch residuals:</p>

<pre><code class="r">res.hare=res4$standardized.residuals[,1]
res.lynx=res4$standardized.residuals[,2]
t=res4$residuals.time

res.hare2=res.hare[!is.na(res.hare)]
t.hare=t[!is.na(res.hare)]-1900

res.lynx2=res.lynx[!is.na(res.lynx)]
t.lynx=t[!is.na(res.lynx)]-1900
</code></pre>

<p>Look for auto-correlation:
Raw plot:</p>

<pre><code class="r">plot(t, res.hare,type=&quot;b&quot;,xlab=&quot;Time&quot;, ylab=&quot;Hare residuals&quot;)
plot(t, res.lynx,type=&quot;b&quot;,xlab=&quot;Time&quot;, ylab=&quot;Lynx residuals&quot;)
</code></pre>

<p>Partial auto-correlation plot:</p>

<pre><code class="r">pacf(res.hare2)
pacf(res.lynx2)
</code></pre>

<p>Indication of auto-correlation in lynx residuals</p>

<p>test for autocorrelation as linear regression analysis:</p>

<pre><code class="r">n.hare=length(t.hare)
summary(lm(res.hare2[2:n.hare]~res.hare2[1:(n.hare-1)]))
#Coefficients:
#                          Estimate Std. Error t value Pr(&gt;|t|)
#(Intercept)               -0.01748    0.11350  -0.154    0.878
#res.hare2[1:(n.hare - 1)]  0.12511    0.11853   1.056    0.295

n.lynx=length(t.lynx)
summary(lm(res.lynx2[2:n.lynx]~res.lynx2[1:(n.lynx-1)]))
# res.lynx2[1:(n.lynx - 1)]  0.55608    0.13010   4.274  0.00012 ***

# time trend for residuals?
summary(lm(res.hare2~t.hare))
# t.hare      -0.005578   0.005552  -1.005    0.319

summary(lm(res.lynx2~t.lynx))
# t.lynx      -0.02514    0.01208  -2.082   0.0438 *
</code></pre>

<p>Some indications of auto-correlation here!</p>

<p>Look at non-linear patterns:</p>

<pre><code class="r">library(mgcv)
summary(gam(res.hare2~s(t.hare)))
#          edf Ref.df     F p-value
#s(t.hare)   1      1 1.009   0.319

summary(gam(res.lynx2~s(t.lynx)))
#          edf Ref.df     F p-value  
#s(t.lynx)   1      1 4.235   0.046 *
</code></pre>

<p>Indication of autocorrelation or time trend in lynx residuals, but not
hare residuals. No indications of non-linearity.</p>

<p>Look for whether the distribution is normal:</p>

<pre><code class="r">qqnorm(res.hare2)
qqline(res.hare2)
shapiro.test(res.hare2)
# p-value = 0.07761

qqnorm(res.lynx2)
qqline(res.lynx2)
shapiro.test(res.lynx2)
# p-value = 0.4673
</code></pre>

<p>Looks ok.</p>

<h2>Try new structural model for lynx.</h2>

<p>Two layers for lynx</p>

<pre><code class="r">hare.struct2=layer.series.structure(hare.norm, numlayers=1, prior=p.hare)
lynx.struct2=layer.series.structure(lynx.norm, numlayers=2, prior=p.lynx)
</code></pre>

<p>Run model with predictions forward in time:</p>

<pre><code class="r">res6=layer.analyzer(hare.struct2,lynx.struct2,
  num.MCMC=1000, burnin=10000, spacing=10,num.temp=1,
  causal=cbind(c(2,1,1,1),c(1,1,2,1)), 
  return.residuals=TRUE)
</code></pre>

<p>Compare to previous best model:</p>

<pre><code class="r">compare.layered(res4,res6)
#[1] &quot;compare called&quot;
#            log(lik) Post. Prob.(%)
#Model   1 -101.24052        0.30896
#Model   2  -95.46389       99.69104
</code></pre>

<p>2-layered lynx process gives a better model for the same connections!</p>

<p>Going through the same residual tests reveals no
time trend/autocorrelation in the lynx residuals now.</p>

<pre><code class="r">res.hare=res6$standardized.residuals[,1]
res.lynx=res6$standardized.residuals[,2]
t=res6$residuals.time

res.hare2=res.hare[!is.na(res.hare)]
t.hare=t[!is.na(res.hare)]-1800

res.lynx2=res.lynx[!is.na(res.lynx)]
t.lynx=t[!is.na(res.lynx)]-1800

# Look for auto-correlation:
# Raw plot:
plot(t, res.hare,type=&quot;b&quot;,xlab=&quot;Time&quot;, ylab=&quot;Residuals&quot;)
plot(t, res.lynx,type=&quot;b&quot;,xlab=&quot;Time&quot;, ylab=&quot;Residuals&quot;)

# Partial auto-correlation plot:
pacf(res.hare2)
pacf(res.lynx2)
# Indication of auto-correlation in lynx residuals

# test for autocorrelation as linear regression analysis:
n.hare=length(t.hare)
summary(lm(res.hare2[2:n.hare]~res.hare2[1:(n.hare-1)]))
# res.hare2[1:(n.hare - 1)]  0.12812    0.11845   1.082    0.283

n.lynx=length(t.lynx)
summary(lm(res.lynx2[2:n.lynx]~res.lynx2[1:(n.lynx-1)]))
# res.lynx2[1:(n.lynx - 1)]  0.55725    0.13001   4.286 0.000115 ***

# time trend for residuals?
summary(lm(res.hare2~t.hare))
# t.hare      -0.005746   0.005568  -1.032    0.306

summary(lm(res.lynx2~t.lynx))
# t.lynx      -0.02533    0.01219  -2.079   0.0441 *


library(mgcv)
summary(gam(res.hare2~s(t.hare)))
#          edf Ref.df     F p-value
#s(t.hare)   1      1 1.065   0.306

summary(gam(res.lynx2~s(t.lynx)))
#          edf Ref.df     F p-value
#s(t.lynx)   1      1 4.322   0.044 *
</code></pre>

<p>Slight indication (that would pass the Bonferroni-correction)
of autocorrelation/time trend in lynx residuals, but not
hare residuals.</p>

<h3>Look for whether the distribution is normal:</h3>

<pre><code class="r">qqnorm(res.hare2)
qqline(res.hare2)
shapiro.test(res.hare2)
# p-value = 0.07761

qqnorm(res.lynx2)
qqline(res.lynx2)
shapiro.test(res.lynx2)
# p-value = 0.4729
</code></pre>

<p>No indication of non-normality.</p>

<h3>Traverse connection models between hares and lynx again:</h3>

<pre><code class="r">res.new=traverse.connections.layered(hare.struct2,lynx.struct2, 
  num.MCMC=1000, burnin=10000, spacing=10,use.stationary.stdev=TRUE,
  silent.mode=FALSE)
</code></pre>

<h3>Model comparison (using Bayesian model probabilities):</h3>

<pre><code>compare.layered(res.new)
#            log(lik) Post. Prob.(%)
#Model   1 -100.76421        0.04633
#Model   2  -99.29643        0.20104
#Model   3 -101.30938        0.02686
#Model   4  -99.90567        0.10932
#Model   5  -98.38486        0.50023
#Model   6  -97.90837        0.80558
#Model   7  -98.01382        0.72496
#Model   8  -98.33383        0.52642
#Model   9  -98.21209        0.59457
#Model  10  -98.42398        0.48104
#Model  11 -100.12134        0.08811
#Model  12  -96.28704        4.07608
#Model  13  -96.99870        2.00066
#Model  14  -94.26391       30.82312
#Model  15  -98.01259        0.72585
#Model  16  -95.48237        9.11395
#Model  17  -94.98027       15.05799
#Model  18  -95.43251        9.57985
#Model  19  -94.67187       20.49762
#Model  20  -96.58559        3.02402
#Model  21 -100.88254        0.04116
#Model  22  -99.45364        0.17179
#Model  23 -100.43915        0.06412
#Model  24  -99.65768        0.14008
#Model  25  -98.23818        0.57926
</code></pre>

<p>Best model, model 14 (followed by 17 and 19, then 18 and 16 (same as res6))
Re-create it (in order that later runs do not need to re-do the
connection traversal):</p>

<pre><code class="r">res14=layer.analyzer(hare.struct2,lynx.struct2, 
  num.MCMC=1000, burnin=10000, spacing=10,use.stationary.stdev=TRUE,
  causal=cbind(c(1,1,2,2),c(2,2,1,1),c(2,1,1,1)), return.residuals=TRUE)
</code></pre>

<p>Look at this model:</p>

<pre><code class="r">summary(res14)
#Coefficients:
#                        Mean    Median Lower 95% Upper 95%
#mu_hare             0.067365  0.069041 -0.698753  0.856653
#dt_hare_1           2.373173  2.244645  1.425098  3.930496
#sd_hare_1           0.656256  0.646259  0.484738  0.892410
#obs_sd_hare         0.081879  0.064623  0.007445  0.249914
#mu_lynx            -0.013805 -0.015352 -0.397429  0.382947
#dt_lynx_1           1.448122  1.427379  0.812462  2.271165
#sd_lynx_1           0.073013  0.058676  0.005698  0.212808
#dt_lynx_2           2.728232  2.591797  1.721150  4.945554
#sd_lynx_2           1.181581  1.134244  0.765235  1.893839
#obs_sd_lynx         0.050966  0.042602  0.005949  0.135427
#beta_hare,1_lynx,2  1.097380  1.080033  0.289356  2.019172
#beta_lynx,2_hare,1  0.824386  0.816397  0.097219  1.516054
#beta_lynx,1_hare,1 -1.449238 -1.414978 -2.325471 -0.726898
#complex.eigen       0.997000  1.000000  1.000000  1.000000
#cycle01            19.026284 17.057398 12.609293 33.171597
</code></pre>

<p>The model still has a positive-negative feedback loop, causing
pseudo-cyclic behaviour. It is running positive from hares to the
second lynx layer, positive from the second lynx layer to the
first lynx layer (this is always so) and negative from the first lynx
layer to hares. There is however also a positive connection going
from the second lynx layer to the hare process, which is a bit more
&#39;difficult to interpret.</p>

<p>Possible Interpretation: The second lynx layer is a mixture of everything
that affects lynx reqruitment; environment including the number of hares
available. The environment (excluding the hares) also affects the hare
numbers in a similar way as it affects the lynx numbers.</p>

<h3>Make an even bigger model, with 3-layered lynx process.</h3>

<p>We hope here to separate environment
(layer 3) and lynx requirement (layer 2):</p>

<pre><code class="r">hare.struct3=layer.series.structure(hare.norm, numlayers=1, prior=p.hare)
lynx.struct3=layer.series.structure(lynx.norm, numlayers=3, prior=p.lynx)

res26=layer.analyzer(hare.struct3,lynx.struct3,
  num.MCMC=1000, burnin=10000, spacing=10,num.temp=1,
  causal=cbind(c(2,3,1,1),c(1,1,2,2),c(2,1,1,1)), 
  return.residuals=TRUE)
</code></pre>

<p>Compare this to the previously best model </p>

<pre><code class="r">compare.layered(res.new[[14]], res26)
#           log(lik) Post. Prob.(%)
#Model   1 -94.28952         77.853
#Model   2 -95.54664         22.147
</code></pre>

<p>Didn&#39;t work. The 2-layered lynx model is still best.</p>

<h3>Also test 2 layers for hares:</h3>

<pre><code class="r">hare.struct4=layer.series.structure(hare.norm, numlayers=2, prior=p.hare)
lynx.struct4=layer.series.structure(lynx.norm, numlayers=2, prior=p.lynx)

res27=layer.analyzer(hare.struct4,lynx.struct4,
  num.MCMC=1000, burnin=10000, spacing=10,num.temp=1,
  causal=cbind(c(2,2,1,1),c(1,1,2,2),c(2,1,1,1)), 
  return.residuals=TRUE)

compare.layered(res.new[[14]], res27)
#           log(lik) Post. Prob.(%)
#Model   1 -94.28952       80.54316
#Model   2 -95.71011       19.45684
</code></pre>

<p>Didn&#39;t work either. We&#39;ll settle on 2 layers for lynx, with
connections going both ways between the second layer for lynx and
the only layer for hares.</p>

</body>

</html>
